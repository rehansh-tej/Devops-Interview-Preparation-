If your recently created Nginx pod is in a Pending state, you need to troubleshoot it using the following steps:


---

1. Check Pod Status

Run the following command to get the pod status and reason for being Pending:

kubectl get pods -o wide

Look at the STATUS and AGE columns.


---

2. Describe the Pod for More Details

kubectl describe pod <nginx-pod-name>

Look for Events at the bottom.

Check for messages like:

FailedScheduling – Indicates scheduling issues.

Insufficient CPU or Memory – Node doesn't have enough resources.

Unschedulable – Constraints preventing scheduling.




---

3. Check if Any Node Can Schedule the Pod

kubectl get nodes

If nodes are NotReady, your cluster might have issues.

If nodes have Taints, they may prevent scheduling.


To see taints on nodes:

kubectl describe node <node-name> | grep Taint

If needed, remove a taint:

kubectl taint nodes <node-name> <taint-key>:NoSchedule-


---

4. Check if There's an Issue with Resource Requests

If the pod requests more CPU/memory than available, it stays Pending.

Run:

kubectl get pod <nginx-pod-name> -o yaml | grep -A5 resources

If limits are too high, edit the deployment:

kubectl edit deployment <deployment-name>

Reduce resource requests under:

resources:
  requests:
    cpu: "100m"
    memory: "128Mi"


---

5. Check if There’s a NodeSelector Issue

If the pod has a nodeSelector that doesn’t match any available node, it won’t be scheduled.

Check the pod’s node selector:

kubectl get pod <nginx-pod-name> -o yaml | grep -A3 nodeSelector

If incorrect, edit the deployment and remove the selector.


---

6. Check if There’s a Storage Issue (PVC Pending)

If the pod needs a Persistent Volume Claim (PVC), but it’s not bound, it remains Pending.

Check PVC status:

kubectl get pvc

If PVC is Pending, describe it:

kubectl describe pvc <pvc-name>

Fix storage class or create the required PV.


---

7. Check if There’s a Network Policy Blocking Scheduling

If a NetworkPolicy blocks scheduling or prevents communication, list them:

kubectl get networkpolicy -A

Describe any restrictive policies:

kubectl describe networkpolicy <policy-name>

Modify or remove unnecessary policies.


---

8. Check if a PodDisruptionBudget (PDB) is Preventing Scheduling

If the cluster enforces PodDisruptionBudget (PDB) rules, check them:

kubectl get pdb -A

Describe the policy:

kubectl describe pdb <pdb-name>

Adjust limits if needed.


---

9. Check Cluster Events for Additional Clues

kubectl get events --sort-by=.metadata.creationTimestamp

This shows any cluster-wide issues affecting scheduling.


---

Final Steps: Fix and Reschedule

After identifying the issue, you may need to:

Edit the deployment (kubectl edit deployment nginx)

Scale down/up (kubectl scale deployment nginx --replicas=0 && kubectl scale deployment nginx --replicas=1)

Delete & recreate the pod (kubectl delete pod <nginx-pod-name>)


Would you like help analyzing a specific error from the describe pod output?





In Kubernetes, the number of master (control plane) and worker nodes depends on the size, availability, and fault tolerance requirements of your cluster.


---

1. How Many Master and Worker Nodes?

Master Nodes (Control Plane)

Minimum: 1 (for dev/testing)

Production Recommended: 3 or 5

3-master setup is most common (to maintain quorum in etcd).

5 or more masters may be used for high availability (HA) in large clusters.



Worker Nodes

Minimum: 1 (for dev/testing)

Typical Production: 3 to 1000+ (depending on workload)

Can scale horizontally as needed.

The upper limit depends on the cloud provider or infrastructure.




---

2. Use Case & Why

Master Nodes (Control Plane) – Use Case

These manage the cluster state:

Run core components: kube-apiserver, etcd, kube-scheduler, kube-controller-manager.

Responsible for:

Scheduling pods to worker nodes

Maintaining desired state

Responding to cluster changes



Why multiple?

Redundancy and high availability.

If 1 master goes down, others continue managing the cluster.

Etcd (the key-value store) requires a quorum (majority) for consistency.


> 3 Master Nodes = Tolerate 1 failure
5 Master Nodes = Tolerate 2 failures




---

Worker Nodes – Use Case

These run your application workloads (pods, containers):

Responsible for:

Running containers using kubelet and container runtime (e.g., containerd)

Networking via kube-proxy

Reporting node health and metrics



Why multiple?

Distribute workload across multiple nodes.

Improve performance, scalability, and fault tolerance.

If a node fails, pods can be rescheduled to others.



---

Summary Table


---

If you need examples of HA Kubernetes cluster designs (on AWS, Azure, or on-prem), I can provide diagrams or YAMLs. Want that?



If a Kubernetes master node (control plane) goes down, the behavior of the cluster depends on the number of master nodes and whether you're using a Highly Available (HA) setup.


---

Scenarios When Master Node Goes Down


---

1. Single Master Node Setup (Non-HA)

What happens:

Cluster becomes unavailable for management tasks.

You cannot create, update, or delete pods/services/etc.

Existing workloads (pods) on worker nodes continue running.

No new pods will be scheduled if a node or pod fails.

Auto-scaling, self-healing, and deployments will not work.


Example:

You have a test cluster with 1 master + 2 worker nodes.

Master node crashes due to an etcd disk failure.

Existing web app pods on worker nodes still serve traffic.

If one pod crashes, it will not be recreated (since the control plane is down).

kubectl commands fail with connection errors.



---

2. Multi-Master Setup (HA) – 3 or More Masters

What happens:

Kubernetes uses etcd quorum to maintain availability.

As long as a majority of masters (quorum) are healthy, the cluster functions normally.

New pods can be scheduled, deployments proceed, and services continue.

If quorum is lost, control plane operations fail.


Example 1: One master fails (in 3-master setup):

etcd still has quorum (2 of 3 nodes).

Apps are unaffected.

You can still run kubectl, update deployments, etc.


Example 2: Two masters fail (in 3-master setup):

Quorum is lost (1 of 3 alive → no majority).

Control plane is unavailable.

No new changes allowed.

Running apps continue, but failures are not auto-recovered.



---

3. Impact on kubelet and Node-Level Components

kubelet on worker nodes does not depend on master for running already-started pods.

If pods crash, kubelet will attempt to restart them locally (for static pods).

However, scheduled pods via ReplicaSets/Deployments won't be recreated without the master.



---

Summary


---

Best Practices

Always use at least 3 master nodes in production for high availability.

Use etcd backups and external load balancers for master access.

Monitor master node health with tools like Prometheus or Datadog.


Would you like a diagram or YAML config for an HA setup across zones or regions (e.g., AWS/Azure)?


